{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from joblib import Parallel, delayed\n",
    "import numpy as np\n",
    "\n",
    "import Dataset\n",
    "import LinearClassifier\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import *\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "from IPython.display import SVG, clear_output\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "mean = [125.307, 122.95, 113.865]\n",
    "std  = [62.9932, 62.0887, 66.7048]\n",
    "num_classes = 10\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test  = keras.utils.to_categorical(y_test, num_classes)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test  = x_test.astype('float32')\n",
    "img_dims = (32, 32, 3)\n",
    "\n",
    "for i in range(3):\n",
    "    x_train[:,:,:,i] = (x_train[:,:,:,i] - mean[i]) / std[i]\n",
    "    x_test[:,:,:,i] = (x_test[:,:,:,i] - mean[i]) / std[i]\n",
    "\n",
    "x_test1d = x_test.reshape([x_test.shape[0], 3072, 1, 1])\n",
    "x_train1d = x_train.reshape([x_train.shape[0], 3072, 1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import keras\n",
    "\n",
    "# (x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "\n",
    "\n",
    "# importlib.reload(Dataset)  # reload module in case it was modified\n",
    "# # Load dataset\n",
    "# dataset = Dataset.load_cifar()\n",
    "\n",
    "# x_train = dataset['train']['data']\n",
    "# x_train2d = x_train.reshape([x_train.shape[0], 32, 32, 3])\n",
    "# y_labels = dataset['train']['labels']\n",
    "# y_train = np.zeros((50000, 10))\n",
    "# y_train[range(y_train.shape[0]),y_labels] = 1\n",
    "\n",
    "# x_test = dataset['test']['data']\n",
    "# x_test2d = x_test.reshape([x_test.shape[0], 32, 32, 3])\n",
    "# y_labels = dataset['test']['labels']\n",
    "# y_test = np.zeros((10000, 10))\n",
    "# y_test[range(y_test.shape[0]),y_labels] = 1\n",
    "\n",
    "img_dims = (32, 32, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Classifier\n",
    "## Learning Rate\n",
    "Experimenting with multiple learning rates and showing accuracy on test batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(LinearClassifier)  # reload module in case it was modified\n",
    "\n",
    "lr_stats = pd.DataFrame()\n",
    "learning_rates = [.1, .03, .01, .003, .001, .0007, .0005, .0003, .0002, .0001]\n",
    "\n",
    "for learning_rate in learning_rates:\n",
    "    print('Computing learning_rate %f' % learning_rate)\n",
    "    model = LinearClassifier.LinearClassifier(10, 3072, \n",
    "                          loss_calculator=LinearClassifier.SoftmaxCalculator(),\n",
    "                          learning_rate=learning_rate)\n",
    "    stats = {}\n",
    "    stats['learning_rate'] = learning_rate\n",
    "    stats['initial_accuracy'] = model.measure_accuracy(dataset)\n",
    "    model.train(dataset)\n",
    "    stats['final_accuracy'] = model.measure_accuracy(dataset)\n",
    "    lr_stats = lr_stats.append(stats, ignore_index=True)\n",
    "print(lr_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = lr_stats.plot(x='learning_rate', y='final_accuracy',\n",
    "              title='Accuracy', logx=True)\n",
    "lr_stats.plot(x='learning_rate', y='initial_accuracy',\n",
    "              title='Accuracy', logx=True, ax=ax)\n",
    "\n",
    "plt.xlim(max(learning_rates), min(learning_rates))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Rounds\n",
    "Experiment doing multiple rounds on the same training data.\n",
    "\n",
    "Very evident for badly initialized W ($U(0,1)$, for example), less so for properly initialized values ($N(0, sqrt(2/n)$, for example) because accuracy starts high already."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(LinearClassifier)  # reload module in case it was modified\n",
    "\n",
    "tr_stats = pd.DataFrame()\n",
    "learning_rate = 0.0003\n",
    "model = LinearClassifier.LinearClassifier(10, 3072, \n",
    "                      loss_calculator=LinearClassifier.Softmax(),\n",
    "                      learning_rate=learning_rate)\n",
    "for i in range(10):\n",
    "    print('Round', i)\n",
    "    model.train(dataset)\n",
    "    tr_stats = tr_stats.append({'round' : i,\n",
    "                                'accuracy' : model.measure_accuracy(dataset)},\n",
    "                                ignore_index=True)\n",
    "print(tr_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_stats.plot(x='round', y='accuracy', title='Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(LinearClassifier)  # reload module in case it was modified\n",
    "\n",
    "model = LinearClassifier.NeuralNetwork(10, 3072, [200, 100])\n",
    "model.train(dataset)\n",
    "print('accuracy:', model.measure_accuracy(dataset))\n",
    "# model.train(dataset)\n",
    "# print('accuracy:', model.measure_accuracy(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.measure_accuracy(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def show_model(model):\n",
    "    display(SVG(model_to_dot(model).create(prog='dot', format='svg')))\n",
    "\n",
    "class PlotLearning(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.i = 0\n",
    "        self.x = []\n",
    "        self.losses = []\n",
    "        self.val_losses = []\n",
    "        self.acc = []\n",
    "        self.val_acc = []\n",
    "        self.fig = plt.figure()\n",
    "        \n",
    "        self.logs = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        \n",
    "        self.logs.append(logs)\n",
    "        self.x.append(self.i)\n",
    "        self.losses.append(logs.get('loss'))\n",
    "        self.val_losses.append(logs.get('val_loss'))\n",
    "        self.acc.append(logs.get('acc'))\n",
    "        self.val_acc.append(logs.get('val_acc'))\n",
    "        self.i += 1\n",
    "        f, (ax1, ax2) = plt.subplots(1, 2, sharex=True)\n",
    "        \n",
    "#         clear_output(wait=True)\n",
    "        \n",
    "        ax1.set_yscale('log')\n",
    "        ax1.plot(self.x, self.losses, label=\"loss\")\n",
    "        ax1.plot(self.x, self.val_losses, label=\"val_loss\")\n",
    "        ax1.legend()\n",
    "        \n",
    "        ax2.plot(self.x, self.acc, label=\"accuracy\")\n",
    "        ax2.plot(self.x, self.val_acc, label=\"validation accuracy\")\n",
    "        ax2.legend()\n",
    "        \n",
    "        plt.show();\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(units=10, activation='softmax', input_dim=3072))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=20, batch_size=32, validation_data=(x_test, y_test))\n",
    "\n",
    "loss_and_metrics = model.evaluate(x_test, y_test, batch_size=128)\n",
    "print(loss_and_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(units=200, activation='relu', kernel_regularizer=keras.regularizers.l2(.001), input_dim=3072))\n",
    "model.add(Dense(units=100, activation='relu', kernel_regularizer=keras.regularizers.l2(.001)))\n",
    "model.add(Dense(units=10, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=20, batch_size=32, validation_data=(x_test, y_test))\n",
    "\n",
    "loss_and_metrics = model.evaluate(x_test, y_test, batch_size=128)\n",
    "print(loss_and_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional Neural Network\n",
    "#### Naive model\n",
    "This model converges at 0.66 accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(filters=32, kernel_size=5, activation='relu', input_shape=[32, 32, 3]))\n",
    "model.add(Conv2D(filters=64, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(filters=128, kernel_size=3, activation='relu'))\n",
    "model.add(Conv2D(filters=256, kernel_size=3, activation='relu', dilation_rate=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=100, activation='relu'))\n",
    "model.add(Dropout(0.75))\n",
    "model.add(Dense(units=10, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# show_model(model)\n",
    "\n",
    "plot = PlotLearning()\n",
    "log_tensorboard = TensorBoard(log_dir='./logs', write_graph=True, write_grads=True, write_images=True)\n",
    "\n",
    "val_acc = [.1]\n",
    "train_acc = [.1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('models/keras-cifar-cnn.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "50000/50000 [==============================] - 28s 554us/step - loss: 1.0950 - acc: 0.6201 - val_loss: 8.1187 - val_acc: 0.4668\n",
      "Epoch 2/20\n",
      "50000/50000 [==============================] - 28s 554us/step - loss: 1.0741 - acc: 0.6286 - val_loss: 9.9145 - val_acc: 0.3654\n",
      "Epoch 3/20\n",
      "50000/50000 [==============================] - 27s 549us/step - loss: 1.0488 - acc: 0.6379 - val_loss: 8.5557 - val_acc: 0.4434\n",
      "Epoch 4/20\n",
      "50000/50000 [==============================] - 27s 548us/step - loss: 1.0296 - acc: 0.6455 - val_loss: 7.3057 - val_acc: 0.5183\n",
      "Epoch 5/20\n",
      "50000/50000 [==============================] - 27s 544us/step - loss: 1.0080 - acc: 0.6543 - val_loss: 9.7891 - val_acc: 0.3739\n",
      "Epoch 6/20\n",
      "50000/50000 [==============================] - 27s 541us/step - loss: 0.9875 - acc: 0.6592 - val_loss: 8.5666 - val_acc: 0.4460\n",
      "Epoch 7/20\n",
      "50000/50000 [==============================] - 27s 547us/step - loss: 0.9730 - acc: 0.6656 - val_loss: 6.9658 - val_acc: 0.5385\n",
      "Epoch 8/20\n",
      "50000/50000 [==============================] - 27s 543us/step - loss: 0.9531 - acc: 0.6726 - val_loss: 8.5253 - val_acc: 0.4486\n",
      "Epoch 9/20\n",
      "50000/50000 [==============================] - 27s 542us/step - loss: 0.9351 - acc: 0.6781 - val_loss: 7.7268 - val_acc: 0.4963\n",
      "Epoch 10/20\n",
      "50000/50000 [==============================] - 27s 546us/step - loss: 0.9173 - acc: 0.6844 - val_loss: 9.0224 - val_acc: 0.4184\n",
      "Epoch 11/20\n",
      "50000/50000 [==============================] - 27s 544us/step - loss: 0.9007 - acc: 0.6881 - val_loss: 7.7891 - val_acc: 0.4930\n",
      "Epoch 12/20\n",
      "50000/50000 [==============================] - 27s 543us/step - loss: 0.8761 - acc: 0.6973 - val_loss: 8.8241 - val_acc: 0.4288\n",
      "Epoch 13/20\n",
      "50000/50000 [==============================] - 27s 545us/step - loss: 0.8662 - acc: 0.7031 - val_loss: 7.8172 - val_acc: 0.4865\n",
      "Epoch 14/20\n",
      "50000/50000 [==============================] - 27s 544us/step - loss: 0.8473 - acc: 0.7082 - val_loss: 8.1076 - val_acc: 0.4787\n",
      "Epoch 15/20\n",
      "50000/50000 [==============================] - 27s 544us/step - loss: 0.8342 - acc: 0.7129 - val_loss: 7.1005 - val_acc: 0.5351\n",
      "Epoch 16/20\n",
      "50000/50000 [==============================] - 27s 539us/step - loss: 0.8112 - acc: 0.7199 - val_loss: 8.6194 - val_acc: 0.4431\n",
      "Epoch 17/20\n",
      "50000/50000 [==============================] - 28s 554us/step - loss: 0.7955 - acc: 0.7251 - val_loss: 7.7455 - val_acc: 0.4963\n",
      "Epoch 18/20\n",
      "50000/50000 [==============================] - 27s 547us/step - loss: 0.7845 - acc: 0.7292 - val_loss: 8.2773 - val_acc: 0.4636\n",
      "Epoch 19/20\n",
      "50000/50000 [==============================] - 27s 544us/step - loss: 0.7630 - acc: 0.7354 - val_loss: 7.2712 - val_acc: 0.5220\n",
      "Epoch 20/20\n",
      "50000/50000 [==============================] - 27s 536us/step - loss: 0.7521 - acc: 0.7391 - val_loss: 7.5228 - val_acc: 0.5115\n",
      "[0.1, 0.14580000000000001, 0.14610000000000001, 0.24590000000000001, 0.29380000000000001, 0.29880000000000001, 0.30109999999999998, 0.29609999999999997, 0.35499999999999998, 0.3256, 0.31909999999999999, 0.3931, 0.36109999999999998, 0.40670000000000001, 0.3392, 0.25819999999999999, 0.40039999999999998, 0.43440000000000001, 0.35630000000000001, 0.39190000000000003, 0.36909999999999998, 0.46679999999999999, 0.3654, 0.44340000000000002, 0.51829999999999998, 0.37390000000000001, 0.44600000000000001, 0.53849999999999998, 0.4486, 0.49630000000000002, 0.41839999999999999, 0.49299999999999999, 0.42880000000000001, 0.48649999999999999, 0.47870000000000001, 0.53510000000000002, 0.44309999999999999, 0.49630000000000002, 0.46360000000000001, 0.52200000000000002, 0.51149999999999995]\n",
      "[0.1, 0.20526, 0.28841999999046325, 0.35040000000953675, 0.38272000000953676, 0.41164000000953677, 0.43431999999999998, 0.44966, 0.46535999999046324, 0.48271999996185305, 0.49641999998092651, 0.50957999996185299, 0.52620000001907352, 0.53685999996185307, 0.55088000000000004, 0.56447999996185305, 0.57583999996185298, 0.58683999998092651, 0.59619999998092654, 0.60450000000000004, 0.61339999999999995, 0.62006000003814699, 0.62863999998092657, 0.6378999999809265, 0.64549999999999996, 0.65433999998092651, 0.65915999998092656, 0.66555999998092652, 0.67256000003814698, 0.67807999996185297, 0.68436000003814701, 0.68813999998092656, 0.69730000001907344, 0.70312000001907349, 0.70823999998092646, 0.71287999996185303, 0.71988000001907348, 0.725059999961853, 0.72924000003814693, 0.73541999999999996, 0.73906000000000005]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "h = model.fit(x_train, y_train, epochs=20, batch_size=128, validation_data=(x_test, y_test))\n",
    "val_acc += h.history['val_acc']\n",
    "train_acc += h.history['acc']\n",
    "print(val_acc)\n",
    "print(train_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.00001\n",
    "\n",
    "# plot = PlotLearning()\n",
    "while (lr > 0.000005):\n",
    "    print('Traning with lr = %.7f' % lr)\n",
    "    keras.backend.set_value(model.optimizer.lr, lr)\n",
    "    model.fit(x_train2d, y_train, epochs=2, batch_size=32, validation_data=(x_test2d, y_test))\n",
    "    lr *= .95\n",
    "\n",
    "loss_and_metrics = model.evaluate(x_test2d, y_test, batch_size=128)\n",
    "print(loss_and_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importlib.reload(keras.models)\n",
    "# importlib.reload(h5py)\n",
    "\n",
    "model.save('models/keras-cifar-cnn.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fully convolutional model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dims = (32, 32, 3)\n",
    "\n",
    "conv_parameters = {\n",
    "    'padding': 'same',\n",
    "    'activation': 'relu',\n",
    "    'kernel_initializer': 'he_normal',\n",
    "    'kernel_regularizer': keras.regularizers.l2(.01)\n",
    "}\n",
    "\n",
    "inputs = Input(img_dims)\n",
    "# Input: 32x32x3\n",
    "\n",
    "bn0 = BatchNormalization()(inputs)\n",
    "\n",
    "conv1 = Conv2D(filters=32, kernel_size=3, **conv_parameters)(bn0)\n",
    "conv1 = Conv2D(filters=32, kernel_size=3, **conv_parameters)(conv1)\n",
    "pool1 = MaxPooling2D(pool_size=(2,2))(conv1)\n",
    "# pool1's output is 16x16x32\n",
    "bn1 = BatchNormalization()(pool1)\n",
    "\n",
    "conv2 = Conv2D(filters=64, kernel_size=3, **conv_parameters)(bn1)\n",
    "conv2 = Conv2D(filters=64, kernel_size=3, **conv_parameters)(conv2)\n",
    "pool2 = MaxPooling2D(pool_size=(2,2))(conv2)\n",
    "# pool2's output is 8x8x64\n",
    "bn2 = BatchNormalization()(pool2)\n",
    "\n",
    "conv3 = Conv2D(filters=128, kernel_size=3, **conv_parameters)(bn2)\n",
    "conv3 = Conv2D(filters=128, kernel_size=3, **conv_parameters)(conv3)\n",
    "pool3 = MaxPooling2D(pool_size=(2,2))(conv3)\n",
    "# pool3's output is 4x4x128\n",
    "bn3 = BatchNormalization()(pool3)\n",
    "\n",
    "conv4 = Conv2D(filters=256, kernel_size=3, **conv_parameters)(bn3)\n",
    "conv4 = Conv2D(filters=256, kernel_size=3, **conv_parameters)(conv4)\n",
    "pool4 = MaxPooling2D(pool_size=(2,2))(conv4)\n",
    "# pool4's output is 2x2x256\n",
    "\n",
    "# drop = Dropout(.75)(pool4)\n",
    "# conv5 = Conv2D(filters=100, kernel_size=2, activation='relu')(drop)\n",
    "# conv5 = Conv2D(filters=10, kernel_size=1, activation='softmax')(conv5)\n",
    "# pool4's output is 1x1x10\n",
    "\n",
    "\n",
    "flatten = Flatten()(pool4)\n",
    "drop1 = Dropout(0.75)(flatten)\n",
    "\n",
    "fc1 = Dense(units=512, activation='relu')(drop1)\n",
    "drop2 = Dropout(0.75)(fc1)\n",
    "fc2 = Dense(units=256, activation='relu')(drop2)\n",
    "fc3 = Dense(units=10, activation='softmax')(fc2)\n",
    "\n",
    "model = Model(inputs=[inputs], outputs=[fc3])\n",
    "\n",
    "sgd = keras.optimizers.SGD(lr=.01, momentum=0.5, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "val_acc_fc = [.1]\n",
    "train_acc_fc = [.1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = model.fit(x_train2d, y_train, epochs=20, batch_size=128, validation_data=(x_test2d, y_test))\n",
    "val_acc_fc += h.history['val_acc']\n",
    "train_acc_fc += h.history['acc']\n",
    "print(val_acc_fc)\n",
    "print(train_acc_fc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keras.backend.set_value(model.layers[-3].rate, .75)\n",
    "drop1.rate = .99\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(val_acc_fc, label='val_acc')\n",
    "plt.plot(train_acc_fc, label='train_acc')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df['val_acc reg=0.001'] = val_acc\n",
    "df['train_acc reg=0.001'] = train_acc\n",
    "\n",
    "df['val_acc reg=0.01'] = val_acc_reg\n",
    "df['train_acc reg=0.01'] = train_acc_reg\n",
    "\n",
    "df['val_acc reg=0'] = val_acc_no_reg\n",
    "df['train_acc reg=0'] = train_acc_no_reg\n",
    "\n",
    "df['val_acc decay=1e-5'] = val_acc_dec\n",
    "df['train_acc decay=1e-5'] = train_acc_dec\n",
    "\n",
    "df['val_small'] = val_acc_small\n",
    "df['train_small'] = train_acc_small\n",
    "\n",
    "df.to_csv('models/accuracy_df.csv')\n",
    "\n",
    "ax = df.plot()\n",
    "ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hardcoded decay\n",
    "lr = keras.backend.get_value(model.optimizer.lr)\n",
    "target_lr = lr / 10\n",
    "while lr > target_lr:\n",
    "    print('Training with lr = %.7f' % lr)\n",
    "    keras.backend.set_value(model.optimizer.lr, lr)\n",
    "    model.fit(x_train2d, y_train, epochs=5, batch_size=32, validation_data=(x_test2d, y_test))\n",
    "    lr *= .90"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DenseNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3477718\n"
     ]
    }
   ],
   "source": [
    "conv_parameters = {\n",
    "    'padding': 'same',\n",
    "    'activation': 'relu',\n",
    "    'kernel_initializer': 'he_normal',\n",
    "    'kernel_regularizer': keras.regularizers.l2(.0001)\n",
    "}\n",
    "\n",
    "inputs = Input(img_dims)\n",
    "\n",
    "concat = inputs\n",
    "x = Conv2D(filters=32, kernel_size=3, **conv_parameters)(concat)\n",
    "concat = concatenate([x, concat])\n",
    "\n",
    "x = Conv2D(filters=32, kernel_size=3, **conv_parameters)(concat)\n",
    "concat = concatenate([x, concat])\n",
    "\n",
    "x = Conv2D(filters=32, kernel_size=3, **conv_parameters)(concat)\n",
    "concat = concatenate([x, concat])\n",
    "\n",
    "x = Conv2D(filters=32, kernel_size=3, **conv_parameters)(concat)\n",
    "concat = concatenate([x, concat])\n",
    "\n",
    "x = Conv2D(filters=32, kernel_size=3, **conv_parameters)(concat)\n",
    "concat = concatenate([x, concat])\n",
    "\n",
    "x = Conv2D(filters=32, kernel_size=3, **conv_parameters)(concat)\n",
    "concat = concatenate([x, concat])\n",
    "\n",
    "x = Conv2D(filters=32, kernel_size=3, **conv_parameters)(concat)\n",
    "\n",
    "x = Flatten()(x)\n",
    "\n",
    "x = Dense(100, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(10, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=[inputs], outputs=[x])\n",
    "\n",
    "sgd = keras.optimizers.SGD(lr=.01, momentum=0.5, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "print(model.count_params())\n",
    "\n",
    "val_acc = [.1]\n",
    "train_acc = [.1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "217516\n"
     ]
    }
   ],
   "source": [
    "growth_rate = 12\n",
    "layers_per_block = 12\n",
    "conv_parameters = {\n",
    "    'padding': 'same',\n",
    "    'activation': 'relu',\n",
    "    'kernel_initializer': 'he_normal',\n",
    "    'kernel_regularizer': keras.regularizers.l2(.0001)\n",
    "}\n",
    "\n",
    "def composite_layer(x):\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(filters=growth_rate * 4, kernel_size=1, **conv_parameters)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(filters=growth_rate, kernel_size=3, **conv_parameters)(x)\n",
    "    return x\n",
    "    \n",
    "def dense_block(x):\n",
    "    concat = x\n",
    "    for _ in range(layers_per_block):\n",
    "        x = composite_layer(x)\n",
    "        concat = concatenate([x, concat])\n",
    "    return x\n",
    "    \n",
    "def transition_layer(x):\n",
    "    nchannels = int(x.get_shape()[-1])\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv2D(filters=nchannels // 2, kernel_size=1, **conv_parameters)(x)\n",
    "    x = AveragePooling2D(pool_size=(2,2))(x)\n",
    "    return x\n",
    "\n",
    "inputs = Input(img_dims)\n",
    "\n",
    "x = dense_block(inputs)\n",
    "x = transition_layer(x)\n",
    "\n",
    "x = dense_block(x)\n",
    "x = transition_layer(x)\n",
    "\n",
    "x = dense_block(x)\n",
    "x = transition_layer(x)\n",
    "\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dropout(.5)(x)\n",
    "x = Dense(10, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=[inputs], outputs=[x])\n",
    "\n",
    "sgd = keras.optimizers.SGD(lr=.01, momentum=0.5, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "print(model.count_params())\n",
    "\n",
    "val_acc = [.1]\n",
    "train_acc = [.1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 352s 7ms/step - loss: 53115764.9587 - acc: 0.0990 - val_loss: 52784285.1840 - val_acc: 0.0991\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 363s 7ms/step - loss: 52456043.4125 - acc: 0.0985 - val_loss: 52128495.0016 - val_acc: 0.1000\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 361s 7ms/step - loss: 51804300.0038 - acc: 0.0987 - val_loss: 51480860.6208 - val_acc: 0.1002\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 358s 7ms/step - loss: 51160631.4637 - acc: 0.0996 - val_loss: 50841071.1680 - val_acc: 0.1000\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 360s 7ms/step - loss: 50524685.5232 - acc: 0.0997 - val_loss: 50209076.4992 - val_acc: 0.1000\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 364s 7ms/step - loss: 49896927.0656 - acc: 0.1022 - val_loss: 49585500.0256 - val_acc: 0.1000\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 356s 7ms/step - loss: 49277209.4221 - acc: 0.0979 - val_loss: 48969648.0000 - val_acc: 0.1000\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 333s 7ms/step - loss: 48665256.1882 - acc: 0.0978 - val_loss: 48361567.6672 - val_acc: 0.1000\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 337s 7ms/step - loss: 48060872.8077 - acc: 0.0970 - val_loss: 47760855.1552 - val_acc: 0.1013\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 339s 7ms/step - loss: 47463865.6435 - acc: 0.0988 - val_loss: 47167551.8976 - val_acc: 0.1014\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'val_acc_fc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-aea09f2ba948>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mval_acc_fc\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtrain_acc_fc\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_acc_fc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_acc_fc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'val_acc_fc' is not defined"
     ]
    }
   ],
   "source": [
    "h = model.fit(x_train, y_train, epochs=10, batch_size=32, validation_data=(x_test, y_test))\n",
    "val_acc_fc += h.history['val_acc']\n",
    "train_acc_fc += h.history['acc']\n",
    "print(val_acc_fc)\n",
    "print(train_acc_fc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using real-time data augmentation.\n"
     ]
    }
   ],
   "source": [
    "from DenseNet import densenet, scheduler\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import LearningRateScheduler, TensorBoard, ModelCheckpoint\n",
    "\n",
    "\n",
    "img_input = Input(shape=img_dims)\n",
    "output    = densenet(img_input,num_classes)\n",
    "model     = Model(img_input, output)\n",
    "\n",
    "sgd = keras.optimizers.SGD(lr=.1, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "\n",
    "# set callback\n",
    "tb_cb     = TensorBoard(log_dir='./densenet/', histogram_freq=0)\n",
    "change_lr = LearningRateScheduler(scheduler)\n",
    "ckpt      = ModelCheckpoint('./ckpt.h5', save_best_only=False, mode='auto', period=10)\n",
    "cbks      = [change_lr,tb_cb,ckpt]\n",
    "\n",
    "# set data augmentation\n",
    "print('Using real-time data augmentation.')\n",
    "datagen   = ImageDataGenerator(horizontal_flip=True,width_shift_range=0.125,height_shift_range=0.125,\n",
    "                               fill_mode='constant',cval=0.)\n",
    "\n",
    "datagen.fit(x_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "850606\n"
     ]
    }
   ],
   "source": [
    "print(model.count_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "782/782 [==============================] - 496s 635ms/step - loss: 0.7397 - acc: 0.8700 - val_loss: 0.8474 - val_acc: 0.8352\n",
      "Epoch 2/5\n",
      "782/782 [==============================] - 491s 627ms/step - loss: 0.7115 - acc: 0.8691 - val_loss: 0.8367 - val_acc: 0.8277\n",
      "Epoch 3/5\n",
      "782/782 [==============================] - 474s 607ms/step - loss: 0.7005 - acc: 0.8690 - val_loss: 0.7965 - val_acc: 0.8397\n",
      "Epoch 4/5\n",
      "782/782 [==============================] - 475s 607ms/step - loss: 0.6852 - acc: 0.8726 - val_loss: 0.7806 - val_acc: 0.8398\n",
      "Epoch 5/5\n",
      "782/782 [==============================] - 475s 607ms/step - loss: 0.6885 - acc: 0.8714 - val_loss: 0.9960 - val_acc: 0.7947\n"
     ]
    }
   ],
   "source": [
    "\n",
    "batch_size         = 40         # 64 or 32 or other\n",
    "epochs             = 5\n",
    "iterations         = 782\n",
    "# start training\n",
    "h = model.fit_generator(datagen.flow(x_train, y_train,batch_size=batch_size), steps_per_epoch=iterations, \n",
    "                    epochs=epochs, callbacks=cbks,validation_data=(x_test, y_test))\n",
    "\n",
    "val_acc += h.history['val_acc']\n",
    "train_acc += h.history['acc']\n",
    "\n",
    "model.save('densenet.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0b6f9d86a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(val_acc, label='val_acc')\n",
    "plt.plot(train_acc, label='train_acc')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow\n",
    "### Linear classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=[None, 3072],name='input')\n",
    "W = tf.Variable(tf.zeros([3072, 10]), name='weights')\n",
    "b = tf.Variable(tf.zeros([10]), name='biases')\n",
    "\n",
    "Y = tf.nn.softmax(tf.matmul(X, W) + b, name='model')\n",
    "Y_ = tf.placeholder(tf.float32, shape=[None, 10], name='expected_labels')\n",
    "\n",
    "# loss function\n",
    "cross_entropy = -tf.reduce_sum(Y_ * tf.log(Y))\n",
    "\n",
    "# % of correct answers found in batch\n",
    "is_correct = tf.equal(tf.argmax(Y,1), tf.argmax(Y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "\n",
    "global_step = tf.Variable(0, trainable=False)\n",
    "starter_learning_rate = 0.001\n",
    "learning_rate = tf.train.exponential_decay(starter_learning_rate, global_step,\n",
    "                                           100000, 0.96, staircase=True)\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.003)\n",
    "train_step = optimizer.minimize(cross_entropy, global_step=global_step)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "batch_size = 100\n",
    "test_data = {X: x_test, Y_: y_test}\n",
    "\n",
    "for i in range(1000):\n",
    "    # load batch of images and correct answers\n",
    "    idx = np.random.randint(x_train.shape[0], size=batch_size)\n",
    "    batch_x = x_train[idx]\n",
    "    batch_y = y_train[idx]\n",
    "    train_data={X: batch_x, Y_: batch_y}\n",
    "\n",
    "    # train\n",
    "    sess.run(train_step, feed_dict=train_data)\n",
    "    \n",
    "    a,c = sess.run([accuracy, cross_entropy], feed_dict=test_data)\n",
    "    print(a, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# success ?\n",
    "test_data = {X: x_test, Y_: y_test}\n",
    "a,c = sess.run([accuracy, cross_entropy], feed_dict=test_data)\n",
    "print(a, c)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
